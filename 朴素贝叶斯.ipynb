{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####极大似然估计\n",
    "import pandas as pd    #用来读取数据\n",
    "import numpy as np     #用来处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#定义实现朴素贝叶斯的实现\n",
    "class psbys(object):\n",
    "    #读取训练集\n",
    "    def getTrainSet(self):\n",
    "        dataset=pd.read_csv('naivebayes_data.csv')\n",
    "        datasetNP=np.array(dataset)      #将数据转化为数组\n",
    "        trainData=datasetNP[:,0:datasetNP.shape[1]-1]  #单独存储训练数据的x1，x2\n",
    "        labels=datasetNP[:,datasetNP.shape[1]-1]    #单独存储标签\n",
    "        return trainData,labels\n",
    "    \n",
    "    def classify(self,trainData,labels,features):\n",
    "        #计算每个类的先验概率\n",
    "        labels=list(labels)   #先转换为list类型\n",
    "        P_y={}     #存入label的概率\n",
    "        for label in labels:\n",
    "            P_y[label]=labels.count(label)/float(len(labels))    #计算每个类对应的概率\n",
    "        \n",
    "        #计算标签和属性同时发生的概率\n",
    "        P_xy={}\n",
    "        for y in P_y.keys():\n",
    "            y_index=[i for i,label in enumerate(labels) if label==y]   #找到每个标签对应的样本\n",
    "            for j in range(len(features)):\n",
    "                x_index=[i for i,feature in enumerate(trainData[:,j]) if feature==features[j]]   # 按照属性取值进行划分\n",
    "                xy_count=len(set(x_index)&set(y_index))   #显示连个列表相同的元素\n",
    "                pkey=str(features[j])+'*'+str(y)\n",
    "                P_xy[pkey]=xy_count / float(len(labels))  #计算联合分布\n",
    "        \n",
    "        #求条件概率\n",
    "        P={}\n",
    "        for y in P_y.keys():\n",
    "            for x in features:\n",
    "                pkey=str(x)+'|'+str(y)\n",
    "                P[pkey]=P_xy[str(x)+'*'+str(y)]/float(P_y[y])   #针对每个标签计算条件概率\n",
    "                \n",
    "        #求待测样本的分类\n",
    "        F={}\n",
    "        for y in P_y:\n",
    "            F[y]=P_y[y]\n",
    "            for x in features:\n",
    "                F[y]=F[y]*P[str(x)+'|'+str(y)]     #P[y|X]=P[X|y]*P[y]/P[X]\n",
    "        features_label=max(F,key=F.get)  #取概率最大值\n",
    "        return features_label\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 'S'] 属于 -1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "if __name__=='__main__':\n",
    "    nb=psbys()\n",
    "    #训练数据\n",
    "    trainData,labels=nb.getTrainSet()\n",
    "    #x1,x2\n",
    "    features=[2,'S']\n",
    "    # 返回结果\n",
    "    result=nb.classify(trainData,labels,features)\n",
    "    print (features,'属于',result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯估计接口（拉普拉斯平滑）\n",
    "# λ=1  K=2， S=3； λ=1 拉普拉斯平滑\n",
    "class NavieBayesB(object):\n",
    "    def __init__(self):\n",
    "        self.A = 1    # 即λ=1\n",
    "        self.K = 2\n",
    "        self.S = 3\n",
    "\n",
    "    def getTrainSet(self):\n",
    "        trainSet = pd.read_csv('naivebayes_data.csv')\n",
    "        trainSetNP = np.array(trainSet)     #由dataframe类型转换为数组类型\n",
    "        trainData = trainSetNP[:,0:trainSetNP.shape[1]-1]     #训练数据x1,x2\n",
    "        labels = trainSetNP[:,trainSetNP.shape[1]-1]          #训练数据所对应的所属类型Y\n",
    "        return trainData, labels\n",
    "\n",
    "    def classify(self, trainData, labels, features):\n",
    "        labels = list(labels)    #转换为list类型\n",
    "        #求先验概率\n",
    "        P_y = {}\n",
    "        for label in labels:\n",
    "            P_y[label] = (labels.count(label) + self.A) / float(len(labels) + self.K*self.A)\n",
    "\n",
    "        #求条件概率\n",
    "        P = {}\n",
    "        for y in P_y.keys():\n",
    "            y_index = [i for i, label in enumerate(labels) if label == y]   # y在labels中的所有下标\n",
    "            y_count = labels.count(y)     # y在labels中出现的次数\n",
    "            for j in range(len(features)):\n",
    "                pkey = str(features[j]) + '|' + str(y)\n",
    "                x_index = [i for i, x in enumerate(trainData[:,j]) if x == features[j]]   # x在trainData[:,j]中的所有下标\n",
    "                xy_count = len(set(x_index) & set(y_index))   #x y同时出现的次数\n",
    "                P[pkey] = (xy_count + self.A) / float(y_count + self.S*self.A)   #条件概率\n",
    "\n",
    "        #features所属类\n",
    "        F = {}\n",
    "        for y in P_y.keys():\n",
    "            F[y] = P_y[y]\n",
    "            for x in features:\n",
    "                F[y] = F[y] * P[str(x)+'|'+str(y)]\n",
    "\n",
    "        features_y = max(F, key=F.get)   #概率最大值对应的类别\n",
    "        return features_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nb = NavieBayesB()\n",
    "    # 训练数据\n",
    "    trainData, labels = nb.getTrainSet()\n",
    "    # x1,x2\n",
    "    features = [2,'S']\n",
    "    # 该特征应属于哪一类\n",
    "    result = nb.classify(trainData, labels, features)\n",
    "    print features,'属于',result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
