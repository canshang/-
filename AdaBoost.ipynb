{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######训练样本######\n",
    "def load_simple_data():\n",
    "    data_mat = np.matrix([[1.0,2.1],[2.0,1.1],[1.3,1.0],[1.0,1.0],[2.0,1.0]])\n",
    "    class_labels=[1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return data_mat,class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######根据阈值判断每个特征的输出值######\n",
    "#ret_array初始化时不能全1或-1\n",
    "def stump_classify(data_matrix,dimen,threshval,thresh_ineq):\n",
    "    ret_array=zeros((shape(data_matrix)[0],1))\n",
    "    if thresh_ineq==\"lt\":\n",
    "        ret_array[data_matrix[:,dimen]<=threshval]=-1.0\n",
    "    else:\n",
    "        ret_array[data_matrix[:,dimen]>threshval]=1.0\n",
    "    return ret_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######实现单层决策树######\n",
    "#lt_predicted_arr存储小于等于阈值的输出值，gt_predicted_arr存储大于阈值的输出值\n",
    "def build_stump(data_arr,class_labels,D):\n",
    "    data_matrix=mat(data_arr)   #数据集\n",
    "    label_mat=mat(class_labels).T  #标签集\n",
    "    m,n=shape(data_matrix)   #数据集的行、列\n",
    "    num_steps=10.0      #用于设置划分点\n",
    "    best_stump={}\n",
    "    best_class_est=mat(zeros((m,1)))\n",
    "    min_error=inf\n",
    "    \n",
    "    for i in range(n):\n",
    "        range_min=data_matrix[:,i].min()   #数据集中某一列的最小值\n",
    "        range_max=data_matrix[:,i].max()   #数据集中某一列的最大值\n",
    "        step_size=(range_max-range_min)*1.0/num_steps   #用于设置划分点\n",
    "        for j in range(-1,int(num_steps)+1):\n",
    "            thresh_val=(range_min+float(j)*step_size)   #计算其中一个划分点\n",
    "            lt_predicted_arr=zeros((m,1))     #获得析域不等号的值\n",
    "            gt_predicted_arr=zeros((m,1))     #获得大于不等号的值\n",
    "            predicted_arr=zeros((m,1))        #获得最终的预测值\n",
    "            for inequal in [\"lt\",\"gt\"]:\n",
    "                preducted_vals=stump_classify(data_matrix,i,thresh_val,inequal)\n",
    "                if inequal=='lt':\n",
    "                    lt_predicted_arr=preducted_vals\n",
    "                else:\n",
    "                    gt_predicted_arr=preducted_vals\n",
    "            for k in range(m):\n",
    "                predicted_arr[k] = lt_predicted_arr[k]\n",
    "                if(gt_predicted_arr[k] != 0):\n",
    "                    predicted_arr[k] = gt_predicted_arr[k]\n",
    "            err_arr = mat(ones((m, 1)))\n",
    "            err_arr[predicted_arr == label_mat] = 0\n",
    "            weight_error = D.T * err_arr\n",
    "            print(\"min_error = %0.5f, split: dim %d, thresh %0.2f,the weighted error is %0.3f\" %(min_error, i, thresh_val, weight_error))\n",
    "            if(weight_error < min_error):\n",
    "                min_error = weight_error\n",
    "                best_class_est = predicted_arr.copy()\n",
    "                best_stump[\"dim\"] = i\n",
    "                best_stump[\"thresh\"] = thresh_val\n",
    "                best_stump[\"class_est\"] = best_class_est\n",
    "    return best_stump,min_error,best_class_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###根据单层决策树得到一个弱分类器保存在列表中\n",
    "###根据得到的弱分类器输出的预测值和原始值修改权重，减小误差小的点的权重，增大误差大的点的权重。最后误差率等于0则停止迭代。\n",
    "def adaboost_train_DS(data_arr, class_labels, num_it = 40):\n",
    "    weak_class_arr = []\n",
    "    m = shape(data_arr)[0]\n",
    "    D = mat(ones((m, 1)) / m)\n",
    "    agg_class_est = mat(zeros((m, 1)))\n",
    "    counts = 0\n",
    "\n",
    "    for i in range(num_it):\n",
    "        best_stump,error,class_est = build_stump(data_arr, class_labels, D)\n",
    "        print(\"D: \", D.T)\n",
    "        alpha = float(0.5 * log((1.0 - error) / error))\n",
    "        best_stump[\"alpha\"] = alpha\n",
    "        weak_class_arr.append(best_stump)\n",
    "        print(\"class_est: \", class_est.T)\n",
    "        expon = multiply(-1 * alpha * mat(class_labels).T, class_est)\n",
    "        D = multiply(D, exp(expon))\n",
    "        D = D / D.sum()\n",
    "        agg_class_est += alpha * class_est  #预测值\n",
    "        print(\"agg_class_est: \", agg_class_est.T)\n",
    "        agg_errors = multiply(sign(agg_class_est) != mat(class_labels).T, ones((m, 1)))\n",
    "        error_rate = agg_errors.sum() / m\n",
    "        print(\"total error: \", error_rate)\n",
    "        counts += 1\n",
    "        if(error_rate == 0.0):\n",
    "            break\n",
    "    return weak_class_arr,counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###弱分类器：根据每一个弱分类器阈值，输出每个特征的输出值。\n",
    "def Gx(data_matrix, reshval):\n",
    "    m = shape(data_matrix)[0]\n",
    "    result_data = mat(ones((m, 1)))\n",
    "    result_data[data_matrix[:, 0] <= reshval] = -1.0\n",
    "    result_data[data_matrix[:, 0] > reshval] = 1.0\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###根据输出数据，输出实际预测值。\n",
    "def ada_classfiy(input_data, weak_class_arr, counts):\n",
    "    data_matrix = mat(input_data)\n",
    "    m,n = shape(data_matrix)  \n",
    "    agg_class_est = mat(zeros((m, 1)))\n",
    "    for j in range(n):\n",
    "        for i in range(len(weak_class_arr)):\n",
    "            agg_class_est += (weak_class_arr[i][\"alpha\"] * (Gx(input_data[:, j], weak_class_arr[i][\"thresh\"])).T).T\n",
    "    print(agg_class_est)\n",
    "    return sign(agg_class_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###画图###\n",
    "def experiment_plot(data_matrix, agg_class_est):\n",
    "    data_arr_in = data_matrix.getA()\n",
    "    label_arr_in = agg_class_est.getA()\n",
    "    m,n = shape(data_matrix)\n",
    "\n",
    "    for i in range(m):\n",
    "        if(label_arr_in[i, 0] == -1):\n",
    "            plt.plot(data_arr_in[i, 0], data_arr_in[i, 1], \"ob\")\n",
    "        elif(label_arr_in[i, 0] == 1):\n",
    "            plt.plot(data_arr_in[i, 0], data_arr_in[i, 1], \"or\")\n",
    "\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_error = inf, split: dim 0, thresh 0.90,the weighted error is 0.400\n",
      "min_error = 0.40000, split: dim 0, thresh 1.00,the weighted error is 0.400\n",
      "min_error = 0.40000, split: dim 0, thresh 1.10,the weighted error is 0.400\n",
      "min_error = 0.40000, split: dim 0, thresh 1.20,the weighted error is 0.400\n",
      "min_error = 0.40000, split: dim 0, thresh 1.30,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.40,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.50,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.60,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.70,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.80,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 1.90,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 0, thresh 2.00,the weighted error is 0.600\n",
      "min_error = 0.20000, split: dim 1, thresh 0.89,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.00,the weighted error is 0.200\n",
      "min_error = 0.20000, split: dim 1, thresh 1.11,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.22,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.33,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.44,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.55,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.66,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.77,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.88,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 1.99,the weighted error is 0.400\n",
      "min_error = 0.20000, split: dim 1, thresh 2.10,the weighted error is 0.600\n",
      "D:  [[0.2 0.2 0.2 0.2 0.2]]\n",
      "class_est:  [[-1.  1. -1. -1.  1.]]\n",
      "agg_class_est:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2\n",
      "min_error = inf, split: dim 0, thresh 0.90,the weighted error is 0.250\n",
      "min_error = 0.25000, split: dim 0, thresh 1.00,the weighted error is 0.625\n",
      "min_error = 0.25000, split: dim 0, thresh 1.10,the weighted error is 0.625\n",
      "min_error = 0.25000, split: dim 0, thresh 1.20,the weighted error is 0.625\n",
      "min_error = 0.25000, split: dim 0, thresh 1.30,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.40,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.50,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.60,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.70,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.80,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 1.90,the weighted error is 0.500\n",
      "min_error = 0.25000, split: dim 0, thresh 2.00,the weighted error is 0.750\n",
      "min_error = 0.25000, split: dim 1, thresh 0.89,the weighted error is 0.250\n",
      "min_error = 0.25000, split: dim 1, thresh 1.00,the weighted error is 0.125\n",
      "min_error = 0.12500, split: dim 1, thresh 1.11,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.22,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.33,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.44,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.55,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.66,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.77,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.88,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 1.99,the weighted error is 0.250\n",
      "min_error = 0.12500, split: dim 1, thresh 2.10,the weighted error is 0.750\n",
      "D:  [[0.5   0.125 0.125 0.125 0.125]]\n",
      "class_est:  [[ 1.  1. -1. -1. -1.]]\n",
      "agg_class_est:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2\n",
      "min_error = inf, split: dim 0, thresh 0.90,the weighted error is 0.143\n",
      "min_error = 0.14286, split: dim 0, thresh 1.00,the weighted error is 0.357\n",
      "min_error = 0.14286, split: dim 0, thresh 1.10,the weighted error is 0.357\n",
      "min_error = 0.14286, split: dim 0, thresh 1.20,the weighted error is 0.357\n",
      "min_error = 0.14286, split: dim 0, thresh 1.30,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.40,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.50,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.60,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.70,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.80,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 1.90,the weighted error is 0.286\n",
      "min_error = 0.14286, split: dim 0, thresh 2.00,the weighted error is 0.857\n",
      "min_error = 0.14286, split: dim 1, thresh 0.89,the weighted error is 0.143\n",
      "min_error = 0.14286, split: dim 1, thresh 1.00,the weighted error is 0.500\n",
      "min_error = 0.14286, split: dim 1, thresh 1.11,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.22,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.33,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.44,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.55,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.66,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.77,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.88,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 1.99,the weighted error is 0.571\n",
      "min_error = 0.14286, split: dim 1, thresh 2.10,the weighted error is 0.857\n",
      "D:  [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "class_est:  [[1. 1. 1. 1. 1.]]\n",
      "agg_class_est:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0\n",
      "**************************\n",
      "[[ 3.73766962e+00]\n",
      " [-1.54044504e+00]\n",
      " [-1.38629436e+00]\n",
      " [-1.38629436e+00]\n",
      " [ 1.79175947e+00]\n",
      " [-2.22044605e-16]\n",
      " [-2.22044605e-16]\n",
      " [-2.22044605e-16]\n",
      " [-2.22044605e-16]\n",
      " [-2.22044605e-16]]\n",
      "--------------------------\n",
      "[[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    #D = mat(ones((5, 1)) / 5.0)\n",
    "    data_mat,class_labels = load_simple_data()\n",
    "    #build_stump(data_mat, class_labels, D)\n",
    "    weak_class_arr,counts = adaboost_train_DS(data_mat, class_labels)\n",
    "    print(\"**************************\")\n",
    "    data_mat2 = matrix([[1.2, 2.0],\n",
    "                       [1.0, 1.0],\n",
    "                       [0.6, 1.2],\n",
    "                       [0.8, 1.1],\n",
    "                       [1.8, 1.0],\n",
    "                       [2.0, 0.4],\n",
    "                       [1.7, 0.8],\n",
    "                       [3.5, 0.2],\n",
    "                       [2.5, 0.8],\n",
    "                       [2.8, 0.9]])\n",
    "    agg_class_est = ada_classfiy(data_mat2, weak_class_arr, counts)\n",
    "    print(\"--------------------------\")\n",
    "    print(agg_class_est)\n",
    "    experiment_plot(data_mat2, agg_class_est)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
